<p>
The generation of vector embeddings can be automated using commercial or open pre-trained transformer models. 
</p>

<h2>Working with text</h2>
<hr>

<p>
The following example creates a 384-dimension vector of floats. The code sample uses the open <code>all-MiniLM-L6-v2</code> model. To run this example, first create and activate a Python virtual environment on your machine as follows.
</p>

<pre><code>
python -m venv redisvenv
source ./redisvenv/bin/activate
</code></pre>

<p>
Then, you can install the Python library <code>sentence_transformers</code> as follows:
</p>

<pre>pip install sentence_transformers</pre>

And then download the code provided in the file <a href="https://github.com/redislabs-training/ru402/blob/main/courseware/activities/section_2/generate_text_embeddings.py">generate_text_embeddings.py</a>. The first time the sample is executed, the requested embedding model <code>all-MiniLM-L6-v2</code> is downloaded and stored. Wait patiently, this can take a few seconds.


<h2>Working with images</h2>
<hr>

<p>
    You can think of various applications that, based on the similarity of images, implement use cases like product recommendation based on the aspect, object recognition, face recognition, and more. You can convert images to vector embeddings using commercial or free pre-trained models.
</p>

<p>
    As an example, you may use <a href="https://pypi.org/project/imgbeddings/">imgbeddings</a>. This library produces 768-dimension vectors of floats that can be used for image similarity, among other uses. Install the library in the Python virtual environment:
</p>

<pre>pip install imgbeddings</pre>

Then download and run the code provided in the file <a href="https://github.com/redislabs-training/ru402/blob/main/courseware/activities/section_2/generate_image_embeddings.py">generate_image_embeddings.py</a> to print on the screen the first five elements of the vector corresponding to an image downloaded from the Internet.
