<p>
The generation of vector embeddings can be automated using commercial or open pre-trained transformer models. 
</p>

<h2>Working with text</h2>
<hr>

<p>
The following example creates a 384-dimension vector of floats. The code sample uses the open <code>all-MiniLM-L6-v2</code> model. To run this example, you can install the Python library <code>sentence_transformers</code> as follows:
</p>

<pre>pip install sentence_transformers</pre>

And then run this code. The first time it is executed, the request model <code>all-MiniLM-L6-v2</code> is downloaded and stored.

<pre><code>
from sentence_transformers import SentenceTransformer


model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
text = "This is a technical document, it describes the SID sound chip of the Commodore 64" embedding = model.encode(text)

print(embedding[:10])
</code></pre>

<h2>Working with images</h2>
<hr>

<p>
    You can think of various applications that, based on the similarity of images, implement use cases like product recommendation based on the aspect, object recognition, face recognition, and more. You can convert images to vector embeddings using commercial or free pre-trained models.
</p>

<p>
    As an example, you may use <a href="https://pypi.org/project/imgbeddings/">imgbeddings</a>. This library produces 768-dimension vectors of floats that can be used for image similarity, among other uses. Install the library in a Python virtual environment:
</p>

<pre>pip install imgbeddings</pre>

And run the following code to print on the screen the first five elements of the vector corresponding to an image downloaded from the Internet.

<pre><code>
import requests
from PIL import Image
from imgbeddings import imgbeddings


url = "http://images.cocodataset.org/val2017/000000039769.jpg"
image = Image.open(requests.get(url, stream=True).raw)
ibed = imgbeddings()
embedding = ibed.to_embeddings(image)
print(embedding[0][0:5])
</code></pre>

<h2>Summary</h2>
<hr>

<p>
Different types of unstructured data require specific embedding models to perform the conversion to vector, so you will find models for images, audio files, and text, each specialized for the features that must be extracted. Once the model has been evaluated and employed in a project, it is possible to map a dataset to the vector space and work with it. Once each element in your dataset has a vector associated, you can evaluate the similarity between pairs of vectors and determine the semantic similarity of the related objects they represent using a standard method: vector search, which we'll introduce in the next section.
</p>