<p>
    In this activity you will run a simple example to model the sentences considered before:
</p>

<ul>
    <li>"That is a very happy person"</li>
    <li>"That is a happy dog"</li>
    <li>"Today is a sunny day"</li>
</ul>

<p>
    Then, you will test the similarity of the sentence "That is a happy person" to the three sentences. You can create a Python environment and install the required libraries to run the example as follows:
</p>

<pre>
python -m venv redisvenv
source ./redisvenv/bin/activate

pip install numpy
pip install sentence_transformers
</pre>

Once your virtual environment is configured, you can move on to the rest of the tasks.

<ol>
    <li>Download the code provided in the file <a href="https://github.com/redislabs-training/ru402/blob/main/courseware/activities/section_2/cosine_distance.py">cosine_distance.py</a>. </li>
    <li>Study the code example. In particular, focus on the vector embedding generation and the algorithm that computes cosine similarity in the function <code>cosine_similarity(a, b)</code></li>
    <li>Execute the example. The first time the sample is executed, the requested embedding model <code>all-MiniLM-L6-v2</code> is downloaded and stored. Wait patiently, this can take a few seconds.</li>
</ol>

<p>
Running this example returns the following output:
</p>

<pre>
Query: That is a happy person
That is a very happy person  -> similarity score =  0.9429151
That is a happy dog  -> similarity score =  0.6945774
Today is a sunny day  -> similarity score =  0.256876
</pre>

<p>
We could have expected that the sentences "That is a happy person" and "That is a very happy person" represent the pair having the highest similarity score. In the example, we are comparing the angles between pairs of vectors in a 384-dimensional vector space using the cosine distance.
</p>

<div align="center">
    <img width="300px" src="../../images/section_2/ru402_2_2_0_cosine_similarity.png" alt="Cosine similarity between the test vector and the stored vectors">
</div>

<p>
The closest the angle between the two vectors to zero, the closest is the cosine to one, which indicates a higher similarity between the two sentences. 
</p>

<p>
    Congratulations! You are now able to calculate the similarity of vectors to retrieve semantically relevant results!
</p>
