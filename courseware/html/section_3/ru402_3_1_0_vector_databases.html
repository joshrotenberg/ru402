<p>
    Pre-trained machine learning models simplify the job of data scientists and avoid lengthy and complex operations to turn objects into the corresponding vector embedding. However, managing huge datasets for development and production environments becomes challenging, especially when real-time throughput, scalability and high availability are not negotiable requirements.
</p>
<p>
    The availability of machine learning models has boosted the rise of modern use cases, and as a consequence, the development and adoption of vector databases. Vector databases are capable of storing vectors and can index and search the vector space efficiently. 
</p>

<p>
    If on one side vector databases resolve the problem of managing vector and the operations on them, they must be designed to meet specific throughput requirements, ensuring they can handle increasing volumes of data and queries. Hence, it is crucial to ensure the scalability of the data layer and guarantee high availability, with high uptime and uninterrupted access to the stored vector data in case of disaster or maintenance operations.
</p>

<div align="center">
    <img width="600px" src="../../images/section_3/ru402_3_1_0_vector_database.png" alt="Vector databases accelerate semantic search">
</div>

<p>
In the next units, we will learn how Redis Stack is designed to perform Vector Similarity Search across millions of vectors with real-time performance. In addition, we will discover how Redis Enterprise and Redis Cloud are designed for high availability and scalability and allow the design of production-ready modern applications.
</p>