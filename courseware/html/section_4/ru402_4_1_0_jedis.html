
<p>We've provided you with a small example program that uses the <a href="https://github.com/redis/jedis" target="_blank" class="page-link">Jedis</a> client for Java to store and manipulate data in Redis.</p>
<p>The code is located in the <span class="code"><a href="https://github.com/redislabs-training/ru402/tree/main/src/java" target="_blank" class="page-link">src/java/</a></span> folder in the course GitHub repository.  You should have already cloned this repository to your machine as part of the initial course setup step.</p>
<p>Follow the instructions in the <a href="https://github.com/redislabs-training/ru402/blob/main/src/java/README.md" target="_blank" class="page-link">README.md</a> file if you'd like to run the code in your local environment.</p>

<h2>Code Walkthrough</h2>
<hr>

The example is a Java version of the simple Vector Similarity Search example already introduced along the course, where we:

<ol>
    <li>Instantiate the proper embedding model</li>
    <li>Create the index with the desired fields</li>
    <li>Create vectors from the three sentences using the model, and store them</li>
    <li>Consider a sample sentence, calculate the embedding, and perform VSS</li>
</ol>

<h3>Embedding model creation</h3>
<hr>

The embedding model we will be using in this example proceeds from the <a href="http://djl.ai/">Deep Java Library</a>. The dependency can be added to the Maven project as follows:

<textarea rows="11" cols="40" style="margin: 10px 0;border:none;">
<dependency>
    <groupId>ai.djl</groupId>
    <artifactId>api</artifactId>
    <version>0.24.0</version>
</dependency>
<dependency>
    <groupId>ai.djl.huggingface</groupId>
    <artifactId>tokenizers</artifactId>
    <version>0.24.0</version>
</dependency>
</textarea>

The chosen model is <a href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2">all-mpnet-base-v2</a>, which maps sentences and paragraphs to a 768 dimensional dense vector space.

<pre>
Map<String, String> options = Map.of("maxLength", "768",  "modelMaxLength", "768");
    HuggingFaceTokenizer sentenceTokenizer = HuggingFaceTokenizer.newInstance("sentence-transformers/all-mpnet-base-v2", options);
</pre>

<h3>Index creation</h3>
<hr>

In this example, we are modeling simple documents having this structure:

<pre><code>{
    "content": "This is a content",
    "genre": "just-a-genre",
    "embedding": "..."
}
</code></pre>

Provided there is no nested information in our document, the Hash data type fulfills the purpose. In addition to creating an index for the vector embedding, we will create also a full-text index of type <code>TEXT</code> for the <code>content</code> field and an index of type <code>TAG</code> for the <code>genre</code> field. The relevant options for the <code>VECTOR</code> index type are also specified, such as a Euclidean distance, and the vector dimension. 

<pre>
IndexDefinition definition = new IndexDefinition().setPrefixes(new String[]{"doc:"});
Map<String, Object> attr = new HashMap<>();
attr.put("TYPE", "FLOAT32");
attr.put("DIM", 768);
attr.put("DISTANCE_METRIC", "L2");
attr.put("INITIAL_CAP", 3);
Schema schema = new Schema().addTextField("content", 1).addTagField("genre").addHNSWVectorField("embedding", attr);                      
unifiedjedis.ftCreate("vector_idx", IndexOptions.defaultOptions().setDefinition(definition), schema);
</pre>


<h3>Vector embedding generation</h3>
<hr>

Vector embeddings can be created using the model created before. Note that embeddings are stored in Hashes using the binary blob format, used in the example.

<pre>
String sentence1 = "That is a very happy person";
unifiedjedis.hset("doc:1", Map.of(  "content", sentence1, "genre", "persons"));
unifiedjedis.hset("doc:1".getBytes(), "embedding".getBytes(), longArrayToByteArray(sentenceTokenizer.encode(sentence1).getIds()));
</pre>

<blockquote>
Remember that JSON must store vector embeddings as arrays of float. Hence, the related method to be used for JSON documents is provided in the example: <code>longArrayToFloatArray</code>
</blockquote>


<h3>Perform the search</h3>
<hr>

Finally, considering the test sentence "That is a happy person", we perform the KNN search and return the score of the search and the content of the best matches. In this example we are returning the three documents, so you can analyze the score.

<pre>
// This is the test sentence
String sentence = "That is a happy person";

int K = 3;
Query q = new Query("*=>[KNN $K @embedding $BLOB AS score]").
                    returnFields("content", "score").
                    addParam("K", K).
                    addParam("BLOB", longArrayToByteArray(sentenceTokenizer.encode(sentence).getIds())).
                    dialect(2);

// Execute the query
List<Document> docs = unifiedjedis.ftSearch("vector_idx", q).getDocuments();
</pre>