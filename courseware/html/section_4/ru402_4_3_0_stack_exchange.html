
<p>We've provided you with a small example program that uses the <a href="https://github.com/redis/NRedisStack/" target="_blank" class="page-link">NRedisStack</a> client for .NET to store and manipulate data in Redis.</p>
<p>The code is located in the <span class="code"><a href="https://github.com/redislabs-training/ru402/tree/main/src/dotnet" target="_blank" class="page-link">src/dotnet/</a></span> folder in the course GitHub repository. You should have already cloned this repository to your machine as part of the initial course setup step.</p>
<p>Follow the instructions in the <a href="https://github.com/redislabs-training/ru402/blob/main/src/dotnet/README.md" target="_blank" class="page-link">README.md</a> file if you'd like to run the code in your local environment.</p>

<h2>Code Walkthrough</h2>
<hr>

The example is a C# version of the simple Vector Similarity Search example already introduced along the course, where we:

<ol>
    <li>Instantiate the proper embedding model</li>
    <li>Create the index with the desired fields</li>
    <li>Create vectors from the three sentences using the model, and store them</li>
    <li>Consider a sample sentence, calculate the embedding, and perform VSS</li>
</ol>

<h3>Embedding model creation</h3>
<hr>

The embedding model we will be using in this example proceeds from the <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.ml.textcatalog.applywordembedding?view=ml-dotnet" rel="nofollow">TextCatalog.ApplyWordEmbedding</a> library. The dependencies can be added to the project as follows:

<pre>
dotnet add package NRedisStack
dotnet add package Microsoft.ML
</pre>

The chosen model is <a href="https://learn.microsoft.com/en-us/dotnet/api/microsoft.ml.transforms.text.wordembeddingestimator.pretrainedmodelkind?view=ml-dotnet#fields">SentimentSpecificWordEmbedding</a>, which maps sentences and paragraphs to a 150 dimensional dense vector space.

<pre>
private static byte[] GetEmbedding(PredictionEngine<TextData, TransformedTextData> model, string sentence)
{
    // Call the prediction API to convert the text into embedding vector.
    var data = new TextData()
    {
        Text = sentence
    };
    var prediction = model.Predict(data);

    // Convert prediction.Features to a binary blob
    float[] floatArray = Array.ConvertAll(prediction.Features, x => (float)x);
    byte[] byteArray = new byte[floatArray.Length * sizeof(float)];
    Buffer.BlockCopy(floatArray, 0, byteArray, 0, byteArray.Length);

    return byteArray;
}
</pre>

<h3>Index creation</h3>
<hr>

In this example, we are modeling simple documents having this structure:

<pre><code>{
    "content": "This is a content",
    "genre": "just-a-genre",
    "embedding": "..."
}
</code></pre>

Provided there is no nested information in our document, the Hash data type fulfills the purpose. In addition to creating an index for the vector embedding, we will create also a full-text index of type <code>TEXT</code> for the <code>content</code> field and an index of type <code>TAG</code> for the <code>genre</code> field. The relevant options for the <code>VECTOR</code> index type are also specified, such as a Euclidean distance, and the vector dimension. You can learn more about the rest of the option from the <a href="https://redis.io/docs/interact/search-and-query/advanced-concepts/vectors/">documentation</a>.

<pre>
private static void CreateIndex(){
    ConnectionMultiplexer redis = ConnectionMultiplexer.Connect("localhost:6379");
    IDatabase db = redis.GetDatabase();

    var schema = new Schema()
    .AddTextField(new FieldName("content", "content"))
    .AddTagField(new FieldName("genre", "genre"))
    .AddVectorField("embedding", VectorField.VectorAlgo.HNSW,
        new Dictionary<string, object>()
        {
            ["TYPE"] = "FLOAT32",
            ["DIM"] = "150",
            ["DISTANCE_METRIC"] = "L2"
        }
    );

    SearchCommands ft = db.FT();
    ft.Create(
        "vector_idx",
        new FTCreateParams().On(IndexDataType.HASH).Prefix("doc:"),
        schema);
}
</pre>


<h3>Vector embedding generation</h3>
<hr>

Vector embeddings can be created using the model created before. Note that embeddings are stored in Hashes using the binary blob format, used in the example.

<pre>
var hash1 = new HashEntry[] { 
    new HashEntry("content", "That is a very happy person"), 
    new HashEntry("genre", "persons"),
    new HashEntry("embedding", GetEmbedding(predictionEngine, "That is a very happy person")),
};
db.HashSet("doc:1", hash1);
</pre>

<blockquote>
The function <code>Buffer.BlockCopy</code>, defined in the example, converts the array of floats to a binary blob.
</blockquote>


<h3>Perform the search</h3>
<hr>

Finally, considering the test sentence "That is a happy person", we perform the KNN search and return the score of the search and the content of the best matches. In this example we are returning the three documents, so you can analyze the score.

<pre>
SearchCommands ft = db.FT();
var res = ft.Search("vector_idx",
            new Query("*=>[KNN 3 @embedding $query_vec AS score]")
            .AddParam("query_vec", GetEmbedding(predictionEngine, "That is a happy person"))
            .ReturnFields(new FieldName("content", "content"), new FieldName("score", "score"))
            .SetSortBy("score")
            .Dialect(2));
</pre>